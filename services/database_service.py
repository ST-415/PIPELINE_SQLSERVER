"""
Database Service ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PIPELINE_SQLSERVER

‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á SQL Server
"""

import logging
import os
from tkinter import messagebox
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
from sqlalchemy import create_engine, text
from sqlalchemy.exc import DBAPIError, ProgrammingError

from config.database import DatabaseConfig
from constants import DatabaseConstants, ErrorMessages, SuccessMessages
from .permission_checker_service import PermissionCheckerService

class DatabaseService:
    """
    ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• SQL Server
    
    ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ schema
    """
    
    def __init__(self) -> None:
        """
        ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô DatabaseService
        
        ‡∏™‡∏£‡πâ‡∏≤‡∏á database config, engine ‡πÅ‡∏•‡∏∞ logger
        """
        self.db_config = DatabaseConfig()
        self.engine = self.db_config.get_engine()
        self.logger = logging.getLogger(__name__)
        self.permission_checker = None  # ‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≠‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

    def _get_permission_checker(self, log_callback=None):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ PermissionCheckerService"""
        if self.permission_checker is None:
            # ‡πÉ‡∏ä‡πâ silent callback ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GUI
            default_callback = log_callback or (lambda msg: None)
            self.permission_checker = PermissionCheckerService(
                engine=self.engine, 
                log_callback=default_callback
            )
        return self.permission_checker

    def check_permissions(self, schema_name: str = 'bronze', log_callback=None) -> Dict:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå SQL Server ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        
        Args:
            schema_name: ‡∏ä‡∏∑‡πà‡∏≠ schema ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
            log_callback: ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á log (None = ‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á log)
            
        Returns:
            Dict: ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå
        """
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GUI ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏™‡∏î‡∏á log ‡πÉ‡∏ô CLI
        silent_callback = lambda msg: None  # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏á‡∏µ‡∏¢‡∏ö
        checker = self._get_permission_checker(silent_callback if log_callback is None else log_callback)
        return checker.check_all_permissions(schema_name)

    def generate_permission_report(self, schema_name: str = 'bronze') -> str:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
        
        Args:
            schema_name: ‡∏ä‡∏∑‡πà‡∏≠ schema ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
            
        Returns:
            str: ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå
        """
        checker = self._get_permission_checker()
        return checker.generate_permission_report(schema_name)

    def check_connection(self, show_warning: bool = True) -> Tuple[bool, str]:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö SQL Server
        
        Returns:
            Tuple[bool, str]: (‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠, ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå)
        """
        try:
            with self.engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            return True, SuccessMessages.DB_CONNECTION_SUCCESS
        except Exception as e:
            error_msg = f"{ErrorMessages.DB_CONNECTION_FAILED}: {e}"
            self.logger.error(error_msg)
            if show_warning:
                messagebox.showwarning("‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", error_msg)
            return False, error_msg

    def test_connection(self, config: Dict[str, Any]) -> bool:
        """
        ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö SQL Server ‡∏î‡πâ‡∏ß‡∏¢ config ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡∏°‡∏≤
        
        Args:
            config (Dict[str, Any]): ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠
            
        Returns:
            bool: True ‡∏´‡∏≤‡∏Å‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à, False ‡∏´‡∏≤‡∏Å‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
        """
        try:
            driver = DatabaseConstants.DEFAULT_DRIVER
            if config["auth_type"] == DatabaseConstants.AUTH_WINDOWS:
                conn_str = (
                    f"mssql+pyodbc://@{config['server']}/{config['database']}?"
                    f"driver={driver}&Trusted_Connection=yes"
                )
            else:
                conn_str = (
                    f"mssql+pyodbc://{config['username']}:{config['password']}@{config['server']}/{config['database']}?"
                    f"driver={driver}"
                )
            engine = create_engine(conn_str)
            with engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            return True
        except Exception as e:
            self.logger.error(f"Connection error: {e}")
            return False

    def update_config(self, server=None, database=None, auth_type=None, username=None, password=None):
        """‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠"""
        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô DatabaseConfig
        self.db_config.update_config(
            server=server,
            database=database,
            auth_type=auth_type,
            username=username,
            password=password
        )
        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï engine
        self.engine = self.db_config.get_engine()

    def ensure_schemas_exist(self, schema_names):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á schema ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏ ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ"""
        try:
            with self.engine.begin() as conn:
                for schema_name in schema_names:
                    conn.execute(text(f"""
                        IF NOT EXISTS (
                            SELECT 1 FROM sys.schemas WHERE name = '{schema_name}'
                        )
                        BEGIN
                            EXEC('CREATE SCHEMA {schema_name}')
                        END
                    """))
            return True, f"‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö/‡∏™‡∏£‡πâ‡∏≤‡∏á schema ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢: {', '.join(schema_names)}"
        except Exception as e:
            error_msg = f"‡∏™‡∏£‡πâ‡∏≤‡∏á schema ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}"
            self.logger.error(error_msg)
            messagebox.showwarning("‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Schema", error_msg)
            return False, error_msg

    def _fix_text_columns_to_nvarchar_max(self, table_name, required_cols, schema_name='bronze', log_func=None):
        """‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô Text() ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô NVARCHAR(MAX) ‡πÉ‡∏ô SQL Server"""
        from sqlalchemy.types import Text
        
        try:
            with self.engine.begin() as conn:
                for col_name, dtype in required_cols.items():
                    if isinstance(dtype, Text):
                        alter_sql = f"ALTER TABLE {schema_name}.{table_name} ALTER COLUMN [{col_name}] NVARCHAR(MAX)"
                        if log_func:
                            log_func(f"üîß ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{col_name}' ‡πÄ‡∏õ‡πá‡∏ô NVARCHAR(MAX)")
                        conn.execute(text(alter_sql))
        except Exception as e:
            if log_func:
                log_func(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Text() ‡πÑ‡∏î‡πâ: {e}")

    def upload_data(self, df, logic_type, required_cols, schema_name='bronze', log_func=None, force_recreate=False):
        """
        ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ï‡∏≤‡∏° config, insert ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÑ‡∏ß‡πâ, ‡∏ñ‡πâ‡∏≤ schema DB ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡πÉ‡∏´‡πâ drop ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
        
        Args:
            df: DataFrame ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
            logic_type: ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå
            required_cols: ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏•‡∏∞‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            schema_name: ‡∏ä‡∏∑‡πà‡∏≠ schema ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            log_func: ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö log
            force_recreate: ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà (‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)
        """
        
        # ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏ú‡πà‡∏≤‡∏ô ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
        if log_func:
            log_func("‚úÖ ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
        
        try:
            import json
            from datetime import datetime
            from sqlalchemy.types import DateTime
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
            if df is None or df.empty:
                return False, "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤"
            
            if not required_cols:
                return False, "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå timestamp
            current_time = datetime.now()
            df['updated_at'] = current_time
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° dtype ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå timestamp
            required_cols['updated_at'] = DateTime()
            
            table_name = None
            try:
                with open('config/column_settings.json', 'r', encoding='utf-8') as f:
                    col_config = json.load(f)
                table_name = col_config.get("__table_names__", {}).get(logic_type)
            except Exception:
                table_name = None
            if not table_name:
                table_name = logic_type

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á schema ‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
            schema_result = self.ensure_schemas_exist([schema_name])
            if not schema_result[0]:
                return False, f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á schema ‡πÑ‡∏î‡πâ: {schema_result[1]}"

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö schema DB ‡∏ß‡πà‡∏≤‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö required_cols ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            from sqlalchemy import inspect
            from sqlalchemy.types import Text
            insp = inspect(self.engine)
            needs_recreate = force_recreate
            
            if insp.has_table(table_name, schema=schema_name) and not force_recreate:
                db_cols = [col['name'] for col in insp.get_columns(table_name, schema=schema_name)]
                db_col_types = {col['name']: str(col['type']).upper() for col in insp.get_columns(table_name, schema=schema_name)}
                config_cols = list(required_cols.keys())
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
                if set(db_cols) != set(config_cols):
                    msg = f"‚ùå ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Ç‡∏≠‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á {schema_name}.{table_name} ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö config"
                    needs_recreate = True
                else:
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö data types ‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏∏‡∏Å‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
                    from sqlalchemy.types import NVARCHAR as SA_NVARCHAR, DateTime as SA_DateTime, DATE as SA_DATE
                    from sqlalchemy.types import Integer as SA_Integer, SmallInteger as SA_SmallInteger, Float as SA_Float, DECIMAL as SA_DECIMAL, Text as SA_Text, Boolean as SA_Boolean

                    def _type_category(type_str: str) -> str:
                        t = (type_str or '').upper()
                        if any(x in t for x in ['INT', 'BIGINT', 'SMALLINT', 'FLOAT', 'DECIMAL', 'NUMERIC', 'REAL', 'MONEY']):
                            return 'NUMERIC'
                        if any(x in t for x in ['DATE', 'DATETIME', 'SMALLDATETIME', 'DATETIME2', 'TIME']):
                            return 'DATETIME'
                        if any(x in t for x in ['BIT', 'BOOLEAN']):
                            return 'BOOLEAN'
                        if any(x in t for x in ['CHAR', 'NCHAR', 'VARCHAR', 'NVARCHAR', 'TEXT']):
                            return 'STRING'
                        return 'OTHER'

                    def _expected_type_str(sa_type_obj) -> str:
                        # ‡πÅ‡∏õ‡∏•‡∏á SQLAlchemy type object ‡πÄ‡∏õ‡πá‡∏ô string ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö DB
                        s = str(sa_type_obj).upper()
                        # Map Text() ‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏õ‡πá‡∏ô NVARCHAR(MAX)
                        if isinstance(sa_type_obj, SA_Text):
                            return 'NVARCHAR(MAX)'
                        return s

                    def _parse_varchar_len(type_str: str) -> int:
                        try:
                            if 'MAX' in type_str.upper():
                                return 2_147_483_647  # ‡πÉ‡∏´‡∏ç‡πà‡∏û‡∏≠‡πÅ‡∏ó‡∏ô MAX
                            if '(' in type_str and ')' in type_str:
                                return int(type_str.split('(')[1].split(')')[0])
                        except Exception:
                            pass
                        return -1

                    for col_name, expected_dtype in required_cols.items():
                        db_type = db_col_types.get(col_name, '')
                        expected_str = _expected_type_str(expected_dtype)
                        cat_db = _type_category(db_type)
                        cat_expected = _type_category(expected_str)

                        # ‡∏Å‡∏£‡∏ì‡∏µ Text() ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô NVARCHAR(MAX)
                        if isinstance(expected_dtype, SA_Text):
                            if 'NVARCHAR(MAX)' not in db_type and 'TEXT' not in db_type:
                                if log_func:
                                    log_func(f"‚ùå ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{col_name}' ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô NVARCHAR(MAX) ‡πÅ‡∏ï‡πà‡πÄ‡∏õ‡πá‡∏ô {db_type}")
                                needs_recreate = True
                                break

                        # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö mismatch ‡∏Ç‡∏≠‡∏á‡∏´‡∏°‡∏ß‡∏î‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏ä‡πà‡∏ô STRING ‚Üî NUMERIC)
                        if cat_db != cat_expected:
                            if log_func:
                                log_func(f"‚ùå ‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{col_name}' ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô (DB: {db_type} | Expected: {expected_str})")
                            needs_recreate = True
                            break

                        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô STRING ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß NVARCHAR
                        if cat_expected == 'STRING' and 'NVARCHAR' in expected_str:
                            exp_len = _parse_varchar_len(expected_str)
                            act_len = _parse_varchar_len(db_type)
                            if act_len != -1 and exp_len != -1 and act_len < exp_len:
                                if log_func:
                                    log_func(f"‚ùå ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß NVARCHAR ‡∏Ç‡∏≠‡∏á '{col_name}' ‡πÑ‡∏°‡πà‡∏û‡∏≠ (DB: {db_type} | Expected: {expected_str})")
                                needs_recreate = True
                                break
            
            # ------------------------------
            # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÉ‡∏´‡∏°‡πà: Ingest ‚Üí NVARCHAR(MAX) staging ‚Üí SQL ‡πÅ‡∏õ‡∏•‡∏á‡∏´‡∏•‡∏±‡∏á‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤
            # ------------------------------
            # 1) ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á staging ‡∏î‡πâ‡∏ß‡∏¢ NVARCHAR(MAX) ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            staging_table = f"{table_name}__stg"
            staging_cols = list(required_cols.keys())
            with self.engine.begin() as conn:
                # ‡∏•‡∏ö staging table ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
                conn.execute(text(f"""
                    IF OBJECT_ID('{schema_name}.{staging_table}', 'U') IS NOT NULL
                        DROP TABLE {schema_name}.{staging_table};
                """))
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á staging table ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô NVARCHAR(MAX) ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
                cols_sql = ", ".join([f"[{c}] NVARCHAR(MAX) NULL" for c in staging_cols])
                conn.execute(text(f"CREATE TABLE {schema_name}.{staging_table} ({cols_sql})"))
                if log_func:
                    log_func(f"üì¶ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤: {schema_name}.{staging_table} (NVARCHAR(MAX) ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå)")

            # 2) ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤ staging ‡∏î‡πâ‡∏ß‡∏¢ pandas.to_sql
            if len(df) > 10000:
                if log_func:
                    log_func(f"üìä ‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà ({len(df):,} ‡πÅ‡∏ñ‡∏ß) - ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ö‡∏ö chunked ‡πÑ‡∏õ‡∏¢‡∏±‡∏á staging")
                chunk_size = 5000
                total_chunks = (len(df) + chunk_size - 1) // chunk_size
                for i in range(0, len(df), chunk_size):
                    chunk = df.iloc[i:i+chunk_size]
                    chunk[staging_cols].to_sql(
                        name=staging_table,
                        con=self.engine,
                        schema=schema_name,
                        if_exists='append',
                        index=False
                    )
                    chunk_num = (i // chunk_size) + 1
                    if log_func:
                        log_func(f"üì§ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î staging chunk {chunk_num}/{total_chunks}: {len(chunk):,} ‡πÅ‡∏ñ‡∏ß")
            else:
                if log_func:
                    log_func(f"üì§ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {len(df):,} ‡πÅ‡∏ñ‡∏ß ‚Üí {schema_name}.{staging_table}")
                df[staging_cols].to_sql(
                    name=staging_table,
                    con=self.engine,
                    schema=schema_name,
                    if_exists='append',
                    index=False
                )

            # 3) ‡∏™‡∏£‡πâ‡∏≤‡∏á/‡∏£‡∏µ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á‡∏ï‡∏≤‡∏° dtype config (‡πÑ‡∏°‡πà auto-fix)
            if needs_recreate or not insp.has_table(table_name, schema=schema_name):
                if needs_recreate and log_func:
                    log_func(f"üõ†Ô∏è ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á {schema_name}.{table_name} ‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
                elif log_func:
                    log_func(f"üìã ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á {schema_name}.{table_name} ‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
                
                df.head(0)[list(required_cols.keys())].to_sql(
                    name=table_name,
                    con=self.engine,
                    schema=schema_name,
                    if_exists='replace',
                    index=False,
                    dtype=required_cols
                )
                # ‡∏õ‡∏£‡∏±‡∏ö Text() ‚Üí NVARCHAR(MAX)
                self._fix_text_columns_to_nvarchar_max(table_name, required_cols, schema_name, log_func)
            else:
                # ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á
                if log_func:
                    log_func(f"üßπ ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á {schema_name}.{table_name}")
                with self.engine.begin() as conn:
                    conn.execute(text(f"TRUNCATE TABLE {schema_name}.{table_name}"))

            # 4) ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å staging ‚Üí ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á ‡∏î‡πâ‡∏ß‡∏¢ TRY_CONVERT/REPLACE ‡∏ï‡∏≤‡∏° dtype ‡πÄ‡∏î‡∏¥‡∏°
            from sqlalchemy.types import (
                Integer as SA_Integer,
                SmallInteger as SA_SmallInteger,
                Float as SA_Float,
                DECIMAL as SA_DECIMAL,
                DATE as SA_DATE,
                DateTime as SA_DateTime,
                NVARCHAR as SA_NVARCHAR,
                Text as SA_Text,
                Boolean as SA_Boolean,
            )

            def _sql_type_and_expr(col_name: str, sa_type_obj) -> str:
                col_ref = f"[{col_name}]"
                base = "NULLIF(LTRIM(RTRIM(" + col_ref + ")), '')"
                if isinstance(sa_type_obj, (SA_Integer, SA_SmallInteger)):
                    return f"TRY_CONVERT(INT, REPLACE(REPLACE({base}, ',', ''), ' ', ''))"
                if isinstance(sa_type_obj, SA_Float):
                    return f"TRY_CONVERT(FLOAT, REPLACE(REPLACE({base}, ',', ''), ' ', ''))"
                if isinstance(sa_type_obj, SA_DECIMAL):
                    precision = getattr(sa_type_obj, 'precision', 18) or 18
                    scale = getattr(sa_type_obj, 'scale', 2) or 2
                    return f"TRY_CONVERT(DECIMAL({precision},{scale}), REPLACE(REPLACE({base}, ',', ''), ' ', ''))"
                if isinstance(sa_type_obj, (SA_DATE, SA_DateTime)):
                    # ‡∏•‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: ISO(121), UK(103), US(101)
                    return (
                        f"COALESCE("
                        f"TRY_CONVERT(DATETIME, {base}, 121),"
                        f"TRY_CONVERT(DATETIME, {base}, 103),"
                        f"TRY_CONVERT(DATETIME, {base}, 101)"
                        f")"
                    )
                if isinstance(sa_type_obj, SA_Boolean):
                    return (
                        "CASE "
                        f"WHEN UPPER(LTRIM(RTRIM({col_ref}))) IN ('1','TRUE','Y','YES') THEN 1 "
                        f"WHEN UPPER(LTRIM(RTRIM({col_ref}))) IN ('0','FALSE','N','NO') THEN 0 "
                        "ELSE NULL END"
                    )
                # NVARCHAR(n) / NVARCHAR(MAX)
                target = 'NVARCHAR(MAX)' if isinstance(sa_type_obj, SA_Text) else str(sa_type_obj).upper()
                return f"TRY_CONVERT({target}, {col_ref})"

            select_exprs = []
            for col_name, sa_type in required_cols.items():
                select_exprs.append(f"{_sql_type_and_expr(col_name, sa_type)} AS [{col_name}]")
            select_sql = ", ".join(select_exprs)

            with self.engine.begin() as conn:
                insert_sql = (
                    f"INSERT INTO {schema_name}.{table_name} (" + ", ".join([f"[{c}]" for c in required_cols.keys()]) + ") "
                    f"SELECT {select_sql} FROM {schema_name}.{staging_table}"
                )
                conn.execute(text(insert_sql))

                # ‡∏•‡∏ö staging table ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô
                conn.execute(text(f"DROP TABLE {schema_name}.{staging_table}"))
                if log_func:
                    log_func(f"üóëÔ∏è ‡∏•‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß {schema_name}.{staging_table}")

            return True, f"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‚Üí {schema_name}.{table_name} (‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ NVARCHAR(MAX) ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏≤‡∏° dtype {len(df):,} ‡πÅ‡∏ñ‡∏ß)"
        except Exception as e:
            # ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏ä‡∏µ‡πâ‡πÄ‡∏õ‡πâ‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤
            def _short_exception_message(exc: Exception) -> str:
                try:
                    if isinstance(exc, DBAPIError) and getattr(exc, "orig", None):
                        # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏à‡∏≤‡∏Å DBAPI/pyodbc ‡πÇ‡∏î‡∏¢‡∏ï‡∏±‡∏î SQL ‡πÅ‡∏•‡∏∞ parameters ‡∏ó‡∏¥‡πâ‡∏á
                        orig = exc.orig
                        # pyodbc ‡∏à‡∏∞‡∏°‡∏µ args ‡πÄ‡∏õ‡πá‡∏ô tuple ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß ‡πÄ‡∏£‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏î
                        parts = [str(p) for p in getattr(orig, "args", []) if p]
                        core = parts[-1] if parts else str(exc)
                    else:
                        core = str(exc)
                    # ‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô [SQL: ...] ‡πÅ‡∏•‡∏∞ [parameters: ...] ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
                    for token in ["[SQL:", "[parameters:"]:
                        if token in core:
                            core = core.split(token)[0].strip()
                    # ‡∏¢‡πà‡∏≠‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô (‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å)
                    core = core.splitlines()[0]
                    return core
                except Exception:
                    return str(exc)

            def _detect_problem_columns(df_local, required_map, max_cols: int = 5, max_examples: int = 3):
                import pandas as pd  # ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á import ‡∏ß‡∏ô
                from sqlalchemy.types import (
                    Integer as SA_Integer,
                    SmallInteger as SA_SmallInteger,
                    Float as SA_Float,
                    DECIMAL as SA_DECIMAL,
                    DATE as SA_DATE,
                    DateTime as SA_DateTime,
                    NVARCHAR as SA_NVARCHAR,
                )
                problems = []
                try:
                    for col, dtype in required_map.items():
                        if col not in df_local.columns:
                            continue
                        # ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
                        if isinstance(dtype, (SA_Integer, SA_SmallInteger, SA_Float, SA_DECIMAL)):
                            numeric_series = pd.to_numeric(df_local[col], errors="coerce")
                            mask = numeric_series.isna() & df_local[col].notna()
                            bad_count = int(mask.sum())
                            if bad_count > 0:
                                examples = [str(x) for x in df_local.loc[mask, col].head(max_examples).tolist()]
                                problems.append({
                                    "column": col,
                                    "expected": str(dtype),
                                    "bad_count": bad_count,
                                    "examples": examples,
                                })
                        # ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
                        elif isinstance(dtype, (SA_DATE, SA_DateTime)):
                            parsed = pd.to_datetime(df_local[col], errors="coerce")
                            mask = parsed.isna() & df_local[col].notna()
                            bad_count = int(mask.sum())
                            if bad_count > 0:
                                examples = [str(x) for x in df_local.loc[mask, col].head(max_examples).tolist()]
                                problems.append({
                                    "column": col,
                                    "expected": str(dtype),
                                    "bad_count": bad_count,
                                    "examples": examples,
                                })
                        # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á string (‡∏ñ‡πâ‡∏≤‡∏Å‡∏≥‡∏´‡∏ô‡∏î NVARCHAR(n))
                        elif isinstance(dtype, SA_NVARCHAR) and getattr(dtype, "length", None):
                            max_len = int(dtype.length)
                            str_series = df_local[col].astype(str)
                            mask = str_series.str.len() > max_len
                            bad_count = int(mask.sum())
                            if bad_count > 0:
                                examples = str_series.loc[mask].str[:50].head(max_examples).tolist()
                                problems.append({
                                    "column": col,
                                    "expected": f"NVARCHAR({max_len})",
                                    "bad_count": bad_count,
                                    "examples": examples,
                                })
                        # ‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ
                        if len(problems) >= max_cols:
                            break
                except Exception:
                    pass
                return problems

            short_msg = _short_exception_message(e)
            problem_hints = _detect_problem_columns(df, required_cols)

            if problem_hints:
                lines = [
                    f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {short_msg}",
                    "‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô):",
                ]
                for p in problem_hints:
                    ex = ", ".join(p.get("examples", []))
                    lines.append(f"- {p['column']} (‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤ {p['expected']}) ‡∏ú‡∏¥‡∏î {p['bad_count']:,} ‡πÅ‡∏ñ‡∏ß ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: [{ex}]")
                error_msg = "\n".join(lines)
            else:
                error_msg = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {short_msg}"

            if log_func:
                log_func(f"‚ùå {error_msg}")
            return False, error_msg
