"""
‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Performance Optimizer ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PIPELINE_SQLSERVER

‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Performance Optimizer ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà
"""

import os
import threading
import time
from performance_optimizations import PerformanceOptimizer, LargeFileProcessor, estimate_processing_time, format_file_size

def example_basic_usage():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô"""
    print("=== ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ===")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Performance Optimizer
    def log_callback(message):
        print(f"[LOG] {message}")
    
    optimizer = PerformanceOptimizer(log_callback)
    
    # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà
    file_path = "example_large_file.xlsx"
    if os.path.exists(file_path):
        success, df = optimizer.read_large_file_chunked(file_path, 'excel')
        if success:
            print(f"‚úÖ ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(df):,} ‡πÅ‡∏ñ‡∏ß")
            
            # ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á memory usage
            df = optimizer.optimize_memory_usage(df)
            
            # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö chunk
            chunks = optimizer.process_dataframe_in_chunks(df, chunk_size=5000)
            print(f"üìä ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô {len(chunks)} chunks")
        else:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ")
    else:
        print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {file_path}")

def example_cancellation():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô"""
    print("\n=== ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ===")
    
    def log_callback(message):
        print(f"[LOG] {message}")
    
    optimizer = PerformanceOptimizer(log_callback)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á cancellation token
    cancellation_token = threading.Event()
    optimizer.set_cancellation_token(cancellation_token)
    
    # ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô
    def long_running_task():
        for i in range(10):
            if cancellation_token.is_set():
                print("‚ùå ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ñ‡∏π‡∏Å‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å")
                return
            print(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô... ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô {i+1}/10")
            time.sleep(1)
        print("‚úÖ ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
    
    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÉ‡∏ô thread ‡πÅ‡∏¢‡∏Å
    import threading
    thread = threading.Thread(target=long_running_task)
    thread.start()
    
    # ‡∏£‡∏≠ 3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÅ‡∏•‡πâ‡∏ß‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å
    time.sleep(3)
    print("üõë ‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô...")
    cancellation_token.set()
    
    thread.join()

def example_progress_tracking():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤"""
    print("\n=== ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ===")
    
    def log_callback(message):
        print(f"[LOG] {message}")
    
    optimizer = PerformanceOptimizer(log_callback)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á progress tracker
    total_items = 100
    progress_tracker = optimizer.create_progress_tracker(total_items, "‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    
    # ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
    for i in range(total_items):
        time.sleep(0.1)  # ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        progress, message = progress_tracker()
        print(f"üìä {message}")

def example_large_file_processor():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ LargeFileProcessor"""
    print("\n=== ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ LargeFileProcessor ===")
    
    def log_callback(message):
        print(f"[LOG] {message}")
    
    processor = LargeFileProcessor(log_callback)
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
    def step1_clean_data(df):
        print("üßπ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        return df.dropna()
    
    def step2_transform_data(df):
        print("üîÑ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        return df.fillna(0)
    
    def step3_validate_data(df):
        print("‚úÖ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        return df
    
    processing_steps = [step1_clean_data, step2_transform_data, step3_validate_data]
    
    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå
    file_path = "example_large_file.xlsx"
    if os.path.exists(file_path):
        success, df = processor.process_large_file(file_path, 'excel', processing_steps)
        if success:
            print(f"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(df):,} ‡πÅ‡∏ñ‡∏ß")
        else:
            print("‚ùå ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    else:
        print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {file_path}")

def example_parallel_processing():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö parallel"""
    print("\n=== ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö parallel ===")
    
    def log_callback(message):
        print(f"[LOG] {message}")
    
    optimizer = PerformanceOptimizer(log_callback)
    
    # ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå
    file_paths = [
        "file1.xlsx",
        "file2.xlsx", 
        "file3.xlsx",
        "file4.xlsx"
    ]
    
    def process_file(file_path):
        """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå"""
        print(f"üìÅ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {file_path}")
        time.sleep(2)  # ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        return f"‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô: {file_path}"
    
    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö parallel
    results = optimizer.parallel_process_files(
        file_paths, 
        process_file,
        progress_callback=lambda p, msg: print(f"üìä {msg}: {p*100:.1f}%")
    )
    
    print("üìã ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:")
    for success, result in results:
        status = "‚úÖ" if success else "‚ùå"
        print(f"{status} {result}")

def example_memory_optimization():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á memory"""
    print("\n=== ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á memory ===")
    
    import pandas as pd
    import numpy as np
    
    def log_callback(message):
        print(f"[LOG] {message}")
    
    optimizer = PerformanceOptimizer(log_callback)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
    data = {
        'id': range(100000),
        'name': [f'Name_{i}' for i in range(100000)],
        'value': np.random.randn(100000),
        'category': np.random.choice(['A', 'B', 'C'], 100000)
    }
    
    df = pd.DataFrame(data)
    print(f"üìä DataFrame ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: {len(df):,} ‡πÅ‡∏ñ‡∏ß")
    print(f"üíæ Memory ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB")
    
    # ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á memory
    df_optimized = optimizer.optimize_memory_usage(df)
    
    print(f"üíæ Memory ‡∏´‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á: {df_optimized.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB")

def example_time_estimation():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡πÄ‡∏ß‡∏•‡∏≤"""
    print("\n=== ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡πÄ‡∏ß‡∏•‡∏≤ ===")
    
    # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡πà‡∏≤‡∏á‡πÜ
    file_sizes = [10, 50, 100, 500, 1000]  # MB
    
    for size in file_sizes:
        estimated_time = estimate_processing_time(size, 'standard')
        print(f"üìÅ ‡πÑ‡∏ü‡∏•‡πå {size} MB: ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì {estimated_time:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ({estimated_time/60:.1f} ‡∏ô‡∏≤‡∏ó‡∏µ)")

def example_file_size_formatting():
    """‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå"""
    print("\n=== ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå ===")
    
    sizes = [1024, 1024*1024, 1024*1024*1024, 1024*1024*1024*1024]
    
    for size in sizes:
        formatted = format_file_size(size)
        print(f"üìè {size} bytes = {formatted}")

def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Performance Optimizer")
    print("=" * 60)
    
    try:
        example_basic_usage()
        example_cancellation()
        example_progress_tracking()
        example_large_file_processor()
        example_parallel_processing()
        example_memory_optimization()
        example_time_estimation()
        example_file_size_formatting()
        
        print("\n" + "=" * 60)
        print("‚úÖ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
        
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")

if __name__ == "__main__":
    main() 