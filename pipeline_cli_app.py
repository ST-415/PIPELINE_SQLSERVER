"""
CLI Application ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PIPELINE_SQLSERVER

‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô command line ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏ö‡∏ö batch
"""

import argparse
import logging
import os
from typing import Optional

from config.settings import settings_manager
from constants import AppConstants, PathConstants
from services.database_service import DatabaseService
from services.file_management_service import FileManagementService
from services.file_service import FileService

# ‡∏ó‡∏≥‡πÉ‡∏´‡πâ working directory ‡πÄ‡∏õ‡πá‡∏ô root ‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÄ‡∏™‡∏°‡∏≠
os.chdir(os.path.dirname(os.path.abspath(__file__)))

# Setup logging
logging.basicConfig(
    level=logging.INFO, 
    format=AppConstants.LOG_FORMAT
)

def load_last_path() -> Optional[str]:
    """
    ‡πÇ‡∏´‡∏•‡∏î search path ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå last_path.json (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö GUI)
    
    Returns:
        Optional[str]: search path ‡∏´‡∏£‡∏∑‡∏≠ None ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ
    """
    try:
        import json
        with open('config/last_path.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get('last_path', None)
    except (FileNotFoundError, json.JSONDecodeError, KeyError):
        return None

def process_file(file_path: str, file_service: FileService, db_service: DatabaseService) -> None:
    """
    ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß: ‡∏≠‡πà‡∏≤‡∏ô ‡πÅ‡∏õ‡∏•‡∏á ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î ‡πÅ‡∏•‡∏∞‡∏¢‡πâ‡∏≤‡∏¢ (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
    
    Args:
        file_path: ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        file_service: ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå
        db_service: ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    """
    try:
        logging.info(f"Processing file: {file_path}")
        # 1. ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ï‡∏£‡∏ß‡∏à logic_type ‡∏à‡∏≤‡∏Å header ‡∏Å‡πà‡∏≠‡∏ô (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
        logic_type = file_service.detect_file_type(file_path)
        # 2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ fallback ‡πÄ‡∏î‡∏≤‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
        if not logic_type:
            filename = os.path.basename(file_path)
            if hasattr(file_service, 'column_settings'):
                for key in file_service.column_settings.keys():
                    if key.lower() in filename.lower():
                        logic_type = key
                        break
        if not logic_type:
            logging.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå (logic_type) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {os.path.basename(file_path)} ‡πÑ‡∏î‡πâ ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ")
            return
        logging.info(f"Determined file type as: {logic_type}")
        # 3. ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
        success, df_or_msg = file_service.read_excel_file(file_path, logic_type)
        if not success:
            logging.error(f"{df_or_msg}")
            return
        df = df_or_msg
        # 4. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
        success, result = file_service.validate_columns(df, logic_type)
        if not success:
            logging.error(f"{result}")
            return
        required_cols = file_service.get_required_dtypes(logic_type)
        # 5. ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        success, message = db_service.upload_data(df, logic_type, required_cols)
        if success:
            logging.info(f"Successfully uploaded data from {file_path} to table for logic type {logic_type}.")
            # Move file after upload (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
            move_success, move_result = file_service.move_uploaded_files([file_path], [logic_type])
            if move_success:
                for original_path, new_path in move_result:
                    logging.info(f"Moved file: {original_path} -> {new_path}")
            else:
                logging.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå: {move_result}")
        else:
            logging.error(f"Failed to upload data for {file_path}. Reason: {message}")
    except Exception as e:
        logging.error(f"An unexpected error occurred while processing {file_path}: {e}", exc_info=True)


def validate_source_path() -> Optional[str]:
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î path ‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å last_path.json
    
    Returns:
        Optional[str]: path ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡∏´‡∏£‡∏∑‡∏≠ None
    """
    path = load_last_path()
    if not path:
        logging.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö source path ‡πÉ‡∏ô config/last_path.json")
        logging.info("üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏õ‡∏¥‡∏î GUI ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ source path ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ --source ‡∏£‡∏∞‡∏ö‡∏∏ path")
        return None
    
    if not os.path.isdir(path):
        logging.error(f"‚ùå Source path ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á: {path}")
        return None
    
    logging.info(f"‚úÖ ‡πÉ‡∏ä‡πâ source path: {path}")
    return path


def upload_files_auto_cli(args):
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏ú‡πà‡∏≤‡∏ô CLI
    
    Args:
        args (argparse.Namespace): arguments ‡∏à‡∏≤‡∏Å command line  
    """
    logging.info("Starting CLI auto upload process.")
    
    source_path = args.source
    if not source_path or not os.path.isdir(source_path):
        logging.error(f"Invalid source path: {source_path}")
        return
    
    logging.info(f"Source path: {source_path}")


def process_main_files_step(source_path: str) -> None:
    """
    ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏Å‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
    
    Args:
        source_path (str): ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå
    """
    logging.info("=== ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå ===")
    
    try:
        # ‡πÉ‡∏ä‡πâ logging.info ‡πÄ‡∏õ‡πá‡∏ô log_callback ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CLI (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
        file_service = FileService(search_path=source_path, log_callback=logging.info)
        db_service = DatabaseService()

        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        data_files = file_service.find_data_files()
        
        if not data_files:
            logging.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á")
            return
        
        logging.info(f"‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(data_files)} ‡πÑ‡∏ü‡∏•‡πå ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...")
        
        total_files = len(data_files)
        processed_files = 0
        successful_uploads = 0
        
        for file_path in data_files:
            try:
                processed_files += 1
                
                logging.info(f"üìÅ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {os.path.basename(file_path)} ({processed_files}/{total_files})")
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤ logic_type (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
                logic_type = file_service.detect_file_type(file_path)
                if not logic_type:
                    # ‡∏•‡∏≠‡∏á‡πÄ‡∏î‡∏≤‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
                    filename = os.path.basename(file_path).lower()
                    for key in file_service.column_settings.keys():
                        if key.lower() in filename:
                            logic_type = key
                            break
                
                if not logic_type:
                    logging.info(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå: {os.path.basename(file_path)}")
                    continue
                
                logging.info(f"üìã ‡∏£‡∏∞‡∏ö‡∏∏‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå: {logic_type}")
                
                # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
                success, result = file_service.read_excel_file(file_path, logic_type, use_auto_fix=True)
                if not success:
                    logging.info(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå: {result}")
                    continue
                
                df = result
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
                success, result = file_service.validate_columns(df, logic_type)
                if not success:
                    logging.info(f"‚ùå ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á: {result}")
                    continue
                
                # ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° auto schema update
                required_cols = file_service.get_required_dtypes(logic_type)
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ required_cols ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤
                if not required_cols:
                    logging.info(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {logic_type}")
                    continue
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤
                if df.empty:
                    logging.info(f"‚ùå ‡πÑ‡∏ü‡∏•‡πå {os.path.basename(file_path)} ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
                    continue
                
                logging.info(f"üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(df)} ‡πÅ‡∏ñ‡∏ß ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó {logic_type}")
                
                # ‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏ö auto schema update
                processing_report = {'auto_fixes_applied': True}  # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ auto-fix
                success, message = file_service.upload_data_with_auto_schema_update(
                    df, logic_type, processing_report
                )
                
                if success:
                    logging.info(f"‚úÖ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {message}")
                    successful_uploads += 1
                    
                    # ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI)
                    try:
                        move_success, move_result = file_service.move_uploaded_files([file_path], [logic_type])
                        if move_success:
                            for original_path, new_path in move_result:
                                logging.info(f"üì¶ ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏õ‡∏¢‡∏±‡∏á: {os.path.basename(new_path)}")
                        else:
                            logging.info(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå: {move_result}")
                    except Exception as e:
                        logging.info(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå: {e}")
                else:
                    logging.info(f"‚ùå ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {message}")
                    
            except Exception as e:
                logging.error(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {os.path.basename(file_path)}: {e}")
                continue
        
        # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•
        logging.info(f"üèÅ ‡∏™‡∏£‡∏∏‡∏õ: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {total_files} ‡πÑ‡∏ü‡∏•‡πå ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à {successful_uploads} ‡πÑ‡∏ü‡∏•‡πå")
        
    except Exception as e:
        logging.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏Å: {e}")


def auto_upload_cli(args) -> None:
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏ú‡πà‡∏≤‡∏ô CLI (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI auto process)
    
    Args:
        args: arguments ‡∏à‡∏≤‡∏Å argparse
    """
    logging.info("ü§ñ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏ú‡πà‡∏≤‡∏ô CLI")
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î source path
    source_path = args.source if args.source else validate_source_path()
    
    if not source_path:
        return
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    db_service = DatabaseService()
    success, message = db_service.check_connection()
    if not success:
        logging.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {message}")
        return
    
    logging.info("‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    logging.info("üîê ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    permission_results = db_service.check_permissions('bronze', logging.info)
    
    if not permission_results.get('success', False):
        logging.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠")
        logging.info("üìã ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå:")
        report = db_service.generate_permission_report('bronze')
        for line in report.split('\n'):
            if line.strip():
                logging.info(line)
        return
    
    logging.info("‚úÖ ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
    
    try:
        # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏Å: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå
        process_main_files_step(source_path)
        
        logging.info("üéâ ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡πÅ‡∏•‡πâ‡∏ß")
        
    except Exception as e:
        logging.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥: {e}")


def main():
    """
    Main function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CLI
    """
    parser = argparse.ArgumentParser(description='PIPELINE_SQLSERVER CLI - ‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå Excel/CSV ‡∏™‡∏π‡πà SQL Server')
    
    # Main command
    subparsers = parser.add_subparsers(dest='command', help='‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ')
    
    # Auto upload command
    auto_parser = subparsers.add_parser(
        'auto', 
        help='‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô GUI auto process)'
    )
    auto_parser.add_argument(
        '--source', '-s',
        type=str, 
        help='‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å last_path.json)'
    )
    
    args = parser.parse_args()
    
    if args.command == 'auto':
        auto_upload_cli(args)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()